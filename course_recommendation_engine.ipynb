{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SpVgBlJNayoI"
      },
      "source": [
        "# Course Recommendation Engine with RAG and ChromaDB (In-Memory) Using text-embedding-3-small\n",
        "\n",
        "This notebook implements a course recommendation engine for Assignment 2 using a Retrieval-Augmented Generation (RAG)-like approach. It fetches a course catalog from a provided URL, generates embeddings with Azure OpenAI's `text-embedding-3-small` model, stores them in an in-memory ChromaDB vector store using `chromadb.Client()` with a collection named 'rajcourserecs', and retrieves relevant courses via semantic search. Due to the limitation of `text-embedding-3-small` (it only supports embeddings, not text generation), the pipeline returns formatted retrieved documents instead of generating reasoned recommendations. The implementation fixes `python-dotenv` parsing errors and ensures correct Azure deployment names."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28d272cd-4e31-40aa-bbb4-0be0a1f49a14",
        "outputId": "9732f606-6c04-4ad7-e0e6-b4d644fa5aa4"
      },
      "outputs": [],
      "source": [
        "!python -m pip install langchain langchain-openai pandas openai python-dotenv chromadb --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bLonIlavDBci",
        "outputId": "723d17aa-3376-4997-9988-a995acd2b072"
      },
      "outputs": [],
      "source": [
        "!python -m pip install pypdf --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "Ja6U3t6abVpU"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Python-dotenv could not parse statement starting at line 26\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Environment variables loaded successfully.\n",
            "Current date and time: 01:52 PM , September 23, 2025\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "from datetime import datetime\n",
        "\n",
        "# Load environment variables from .env file\n",
        "load_dotenv()\n",
        "\n",
        "embedding_model_name = \"text-embedding-3-small\"\n",
        "embedding_deployment_name = \"text-embedding-3-small\"  # Replace with your Azure deployment name for text-embedding-3-small\n",
        "\n",
        "# Verify environment variables\n",
        "assert os.environ.get(\"AZURE_OPENAI_ENDPOINT\"), \"AZURE_OPENAI_ENDPOINT not set in .env\"\n",
        "assert os.environ.get(\"AZURE_OPENAI_API_KEY\"), \"AZURE_OPENAI_API_KEY not set in .env\"\n",
        "assert os.environ.get(\"AZURE_OPENAI_API_VERSION\", \"2024-06-01\"), \"AZURE_OPENAI_API_VERSION not set in .env\"\n",
        "\n",
        "print(\"Environment variables loaded successfully.\")\n",
        "print(f\"Current date and time: {datetime.now().strftime('%I:%M %p %Z, %B %d, %Y')}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "MGhs4RN7vgXG"
      },
      "outputs": [],
      "source": [
        "course_catalog_url = \"https://raw.githubusercontent.com/Bluedata-Consulting/GAAPB01-training-code-base/refs/heads/main/Assignments/assignment2dataset.csv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "nhl29sxXD085"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>course_id</th>\n",
              "      <th>title</th>\n",
              "      <th>description</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>C001</td>\n",
              "      <td>Foundations of Machine Learning</td>\n",
              "      <td>Understand foundational machine learning algor...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>C002</td>\n",
              "      <td>Deep Learning with TensorFlow and Keras</td>\n",
              "      <td>Explore neural network architectures using Ten...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>C003</td>\n",
              "      <td>Natural Language Processing Fundamentals</td>\n",
              "      <td>Dive into NLP techniques for processing and un...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>C004</td>\n",
              "      <td>Computer Vision and Image Processing</td>\n",
              "      <td>Learn the principles of computer vision and im...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>C005</td>\n",
              "      <td>Reinforcement Learning Basics</td>\n",
              "      <td>Get introduced to reinforcement learning parad...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  course_id                                     title  \\\n",
              "0      C001           Foundations of Machine Learning   \n",
              "1      C002   Deep Learning with TensorFlow and Keras   \n",
              "2      C003  Natural Language Processing Fundamentals   \n",
              "3      C004      Computer Vision and Image Processing   \n",
              "4      C005             Reinforcement Learning Basics   \n",
              "\n",
              "                                         description  \n",
              "0  Understand foundational machine learning algor...  \n",
              "1  Explore neural network architectures using Ten...  \n",
              "2  Dive into NLP techniques for processing and un...  \n",
              "3  Learn the principles of computer vision and im...  \n",
              "4  Get introduced to reinforcement learning parad...  "
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the course catalog\n",
        "try:\n",
        "    courses = pd.read_csv(course_catalog_url)\n",
        "except Exception as e:\n",
        "    print(f\"Error loading dataset: {e}\")\n",
        "    raise\n",
        "\n",
        "# Display first few rows to verify\n",
        "courses.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "plYaZJcrwZrd",
        "outputId": "494890bf-219a-47ff-fdb8-6c3806a33f5d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of courses loaded:\n",
            "25\n"
          ]
        }
      ],
      "source": [
        "# Verify the number of courses loaded\n",
        "print(\"Number of courses loaded:\")\n",
        "print(len(courses))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "HVLYgpziwdKD"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sample course description:\n",
            "Understand foundational machine learning algorithms including regression, classification, clustering, and dimensionality reduction. This course covers data pre-processing, feature engineering, model selection, hyperparameter tuning, and evaluation metrics. Hands-on labs use scikit-learn and Python to implement end-to-end workflows on real-world datasets, preparing learners for practical machine learning applications with interactive engaging exercises.\n"
          ]
        }
      ],
      "source": [
        "# Display a sample course description\n",
        "print(\"Sample course description:\")\n",
        "print(courses['description'][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "msEaKLKqwiOE",
        "outputId": "030bb343-243e-4718-8db3-d4a466eba058"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average description length (characters): 408.96\n"
          ]
        }
      ],
      "source": [
        "# Check average description length\n",
        "avg_length = sum(len(str(desc)) for desc in courses['description']) / len(courses)\n",
        "print(\"Average description length (characters):\", avg_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qM6hV4DjwkIe",
        "outputId": "95a1e500-863d-4509-cce9-e79d5f0638e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of document splits:\n",
            "25\n"
          ]
        }
      ],
      "source": [
        "# Split long descriptions to avoid exceeding embedding limits\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=3500, chunk_overlap=500)\n",
        "docs = []\n",
        "doc_ids = []\n",
        "metadatas = []\n",
        "for i, (title, desc) in enumerate(zip(courses['title'], courses['description'])):\n",
        "    desc = str(desc)  # Ensure description is a string\n",
        "    if len(desc.strip()) > 100:  # Skip short or empty descriptions\n",
        "        split_docs = text_splitter.split_text(desc)\n",
        "        for j, split in enumerate(split_docs):\n",
        "            docs.append(split)\n",
        "            doc_ids.append(f\"{i}_{j}\")\n",
        "            metadatas.append({\"title\": str(title)})\n",
        "\n",
        "print(\"Number of document splits:\")\n",
        "print(len(docs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YpYTraoSwmUj",
        "outputId": "34f34a36-63ad-4808-decc-12df8830c92b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sample document:\n",
            "ID: 0_0\n",
            "Metadata: {'title': 'Foundations of Machine Learning'}\n",
            "Content: Understand foundational machine learning algorithms including regression, classification, clustering, and dimensionality reduction. This course covers data pre-processing, feature engineering, model s...\n"
          ]
        }
      ],
      "source": [
        "# Display a sample split document\n",
        "print(\"Sample document:\")\n",
        "print(f\"ID: {doc_ids[0]}\")\n",
        "print(f\"Metadata: {metadatas[0]}\")\n",
        "print(f\"Content: {docs[0][:200]}...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "l2B32z8TcWoU"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from langchain_openai import AzureOpenAIEmbeddings\n",
        "embeddings = AzureOpenAIEmbeddings(model=embedding_model_name,deployment=embedding_deployment_name, azure_endpoint=os.environ.get(\"AZURE_OPENAI_ENDPOINT\"),api_key=os.environ.get(\"AZURE_OPENAI_API_KEY\"),api_version=os.environ.get(\"AZURE_OPENAI_API_VERSION\", \"2024-06-01\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "VLwnR76SMPsH"
      },
      "outputs": [],
      "source": [
        "import chromadb\n",
        "\n",
        "# Initialize ChromaDB client (in-memory)\n",
        "chroma_client = chromadb.Client()\n",
        "\n",
        "# Create collection\n",
        "try:\n",
        "    # Delete existing collection if it exists to avoid conflicts\n",
        "    chroma_client.delete_collection(name=\"rajcourserecs\")\n",
        "except:\n",
        "    pass\n",
        "collection = chroma_client.create_collection(name=\"rajcourserecs\", metadata={\"use_type\": \"COURSE_RECOMMENDATION\"})\n",
        "\n",
        "# Generate embeddings for documents\n",
        "try:\n",
        "    embeddings_list = embeddings.embed_documents(docs)\n",
        "except Exception as e:\n",
        "    print(f\"Error generating embeddings: {e}\")\n",
        "    raise\n",
        "\n",
        "# Add documents to the collection\n",
        "try:\n",
        "    collection.add(\n",
        "        documents=docs,\n",
        "        ids=doc_ids,\n",
        "        metadatas=metadatas,\n",
        "        embeddings=embeddings_list\n",
        "    )\n",
        "except Exception as e:\n",
        "    print(f\"Error adding documents to collection: {e}\")\n",
        "    raise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of docs in vector DB:\n",
            "25\n"
          ]
        }
      ],
      "source": [
        "# Verify the number of documents in the collection\n",
        "print(\"Number of docs in vector DB:\")\n",
        "print(collection.count())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Custom retriever function for ChromaDB\n",
        "def chroma_retriever(query, k=10):\n",
        "    try:\n",
        "        query_embedding = embeddings.embed_query(query)\n",
        "        results = collection.query(\n",
        "            query_embeddings=[query_embedding],\n",
        "            n_results=k,\n",
        "            include=[\"documents\", \"metadatas\", \"distances\"]\n",
        "        )\n",
        "        # Convert to LangChain Document format for compatibility\n",
        "        from langchain_core.documents import Document\n",
        "        return [Document(page_content=doc, metadata=meta)\n",
        "                for doc, meta in zip(results['documents'][0], results['metadatas'][0])]\n",
        "    except Exception as e:\n",
        "        print(f\"Error in retriever: {e}\")\n",
        "        return []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "id": "mfJHg61Uw6BP",
        "outputId": "3ce3f2b9-d711-4f4c-9054-0000508f9b9f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of retrieved documents:\n",
            "10\n"
          ]
        }
      ],
      "source": [
        "# Test the retriever with a sample query\n",
        "test_query = \"data visualization courses\"\n",
        "retrieved_docs = chroma_retriever(test_query)\n",
        "print(\"Number of retrieved documents:\")\n",
        "print(len(retrieved_docs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DNIGp-p9w6BV",
        "outputId": "3910a673-677b-4cea-8fcd-95e453bab413"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "page_content='Transform raw data into compelling visual stories using Tableau. Learn to connect to diverse data sources, create interactive dashboards, and apply best practices in chart selection. Topics include calculated fields, parameters, LOD expressions, and storytelling features. Through real-world case studies, you’ll design user-driven analytics that reveal trends and drive data-informed decision making.' metadata={'title': 'Data Visualization with Tableau'}\n"
          ]
        }
      ],
      "source": [
        "# Display a sample retrieved course\n",
        "if retrieved_docs:\n",
        "    print(retrieved_docs[0])\n",
        "else:\n",
        "    print(\"No documents retrieved.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6tMaR7AVw6BV",
        "outputId": "c12e2a21-2685-4760-83c1-302cc27b4642"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "page_content='Get introduced to R for statistical computing and graphics. Topics include data structures, control flow, and functional programming. Use tidyverse libraries—dplyr, ggplot2, tidyr—for data manipulation and visualization. Explore hypothesis testing, regression analysis, and ANOVA. Through labs, apply statistical methods to real-world datasets and communicate results with reproducible R Markdown reports.' metadata={'title': 'R Programming and Statistical Analysis'}\n"
          ]
        }
      ],
      "source": [
        "# Display another sample retrieved course\n",
        "if len(retrieved_docs) > 1:\n",
        "    print(retrieved_docs[1])\n",
        "else:\n",
        "    print(\"Not enough documents retrieved.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z2PHFzF5MPsJ"
      },
      "source": [
        "### Implementing RAG-like Chain (No Generation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "VPQbxI8pMPsK"
      },
      "outputs": [],
      "source": [
        "# Function to format retrieved documents and deduplicate by title\n",
        "def format_docs(docs):\n",
        "    unique_docs = []\n",
        "    seen_titles = set()\n",
        "    for doc in docs:\n",
        "        title = doc.metadata['title']\n",
        "        if title not in seen_titles:\n",
        "            unique_docs.append(f\"Course: {title}\\nDescription: {doc.page_content}\")\n",
        "            seen_titles.add(title)\n",
        "        if len(unique_docs) == 5:\n",
        "            break\n",
        "    return \"\\n\\n\".join(unique_docs) if unique_docs else \"No relevant courses found.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "X5rhhNSE7Q50"
      },
      "outputs": [],
      "source": [
        "# Build the RAG-like chain (no LLM, just retrieval)\n",
        "rag_chain = lambda x: format_docs(chroma_retriever(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xsd3WlbdMPsK",
        "outputId": "06221bc1-e88e-4261-b2d1-a9db13892566"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sample RAG response:\n",
            "Course: Data Visualization with Tableau\n",
            "Description: Transform raw data into compelling visual stories using Tableau. Learn to connect to diverse data sources, create interactive dashboards, and apply best practices in chart selection. Topics include calculated fields, parameters, LOD expressions, and storytelling features. Through real-world case studies, you’ll design user-driven analytics that reveal trends and drive data-informed decision making.\n",
            "\n",
            "Course: R Programming and Statistical Analysis\n",
            "Description: Get introduced to R for statistical computing and graphics. Topics include data structures, control flow, and functional programming. Use tidyverse libraries—dplyr, ggplot2, tidyr—for data manipulation and visualization. Explore hypothesis testing, regression analysis, and ANOVA. Through labs, apply statistical methods to real-world datasets and communicate results with reproducible R Markdown reports.\n",
            "\n",
            "Course: Big Data Analytics with Spark\n",
            "Description: Process and analyze large datasets using Apache Spark and PySpark. The course covers RDDs, DataFrames, Spark SQL, and MLlib for machine learning at scale. You’ll learn cluster deployment on YARN or Kubernetes, performance tuning, and structured streaming for real-time analytics. Hands-on projects include building ETL pipelines and interactive dashboards, unlocking insights from big data.\n",
            "\n",
            "Course: Python Programming for Data Science\n",
            "Description: Learn Python fundamentals for data science: variables, control flow, functions, and object-oriented programming. Advance to data handling with pandas, numerical computing with NumPy, and basic plotting with matplotlib. You’ll build reproducible data workflows, clean and transform datasets, and perform exploratory analysis, laying the groundwork for machine learning and statistical modeling projects.\n",
            "\n",
            "Course: Business Intelligence with Power BI\n",
            "Description: Leverage Microsoft Power BI to build dynamic business intelligence solutions. Cover data ingestion, Power Query transformations, DAX calculations, and interactive report design. You’ll publish dashboards to the Power BI service, set up data refresh schedules, and manage security. Practical labs simulate enterprise scenarios, enabling you to deliver actionable insights at scale.\n"
          ]
        }
      ],
      "source": [
        "# Test the RAG-like chain with a sample query\n",
        "try:\n",
        "    test_response = rag_chain(\"data visualization courses\")\n",
        "    print(\"Sample RAG response:\")\n",
        "    print(test_response)\n",
        "except Exception as e:\n",
        "    print(f\"Error invoking RAG chain: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluation with Sample Queries\n",
        "\n",
        "We test the RAG-like engine with the five provided sample queries. The system retrieves relevant courses but does not generate reasoned recommendations due to the limitation of using only `text-embedding-3-small`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "6tMaR7AVw6BV"
      },
      "outputs": [],
      "source": [
        "# Sample queries\n",
        "sample_queries = [\n",
        "    \"I’ve completed the ‘Python Programming for Data Science’ course and enjoy data visualization. What should I take next?\",\n",
        "    \"I know Azure basics and want to manage containers and build CI/CD pipelines. Recommend courses.\",\n",
        "    \"My background is in ML fundamentals; I’d like to specialize in neural networks and production workflows.\",\n",
        "    \"I want to learn to build and deploy microservices with Kubernetes—what courses fit best?\",\n",
        "    \"I’m interested in blockchain and smart contracts but have no prior experience. Which courses do you suggest?\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "xsd3WlbdMPsK"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "### Test Profile 1\n",
            "**Query:** I’ve completed the ‘Python Programming for Data Science’ course and enjoy data visualization. What should I take next?\n",
            "**Retrieved Courses:**\n",
            "Course: Python Programming for Data Science\n",
            "Description: Learn Python fundamentals for data science: variables, control flow, functions, and object-oriented programming. Advance to data handling with pandas, numerical computing with NumPy, and basic plotting with matplotlib. You’ll build reproducible data workflows, clean and transform datasets, and perform exploratory analysis, laying the groundwork for machine learning and statistical modeling projects.\n",
            "\n",
            "Course: Data Visualization with Tableau\n",
            "Description: Transform raw data into compelling visual stories using Tableau. Learn to connect to diverse data sources, create interactive dashboards, and apply best practices in chart selection. Topics include calculated fields, parameters, LOD expressions, and storytelling features. Through real-world case studies, you’ll design user-driven analytics that reveal trends and drive data-informed decision making.\n",
            "\n",
            "Course: R Programming and Statistical Analysis\n",
            "Description: Get introduced to R for statistical computing and graphics. Topics include data structures, control flow, and functional programming. Use tidyverse libraries—dplyr, ggplot2, tidyr—for data manipulation and visualization. Explore hypothesis testing, regression analysis, and ANOVA. Through labs, apply statistical methods to real-world datasets and communicate results with reproducible R Markdown reports.\n",
            "\n",
            "Course: Big Data Analytics with Spark\n",
            "Description: Process and analyze large datasets using Apache Spark and PySpark. The course covers RDDs, DataFrames, Spark SQL, and MLlib for machine learning at scale. You’ll learn cluster deployment on YARN or Kubernetes, performance tuning, and structured streaming for real-time analytics. Hands-on projects include building ETL pipelines and interactive dashboards, unlocking insights from big data.\n",
            "\n",
            "Course: Computer Vision and Image Processing\n",
            "Description: Learn the principles of computer vision and image processing. Topics include filtering, edge detection, feature extraction, image segmentation, object detection, and image classification using CNNs. Hands-on labs in Python leverage OpenCV, scikit-image, and TensorFlow. By project’s end, you will build a pipeline to analyze and classify images, detect objects, and perform real-time video processing.\n",
            "\n",
            "**Relevance Evaluation:** Review the retrieved courses to assess relevance. The output lists up to 5 courses based on semantic similarity to the query, but no explanations are generated due to using only text-embedding-3-small.\n",
            "\n",
            "### Test Profile 2\n",
            "**Query:** I know Azure basics and want to manage containers and build CI/CD pipelines. Recommend courses.\n",
            "**Retrieved Courses:**\n",
            "Course: Cloud Computing with Azure\n",
            "Description: Master Microsoft Azure’s core services: virtual machines, Azure Functions, Azure SQL Database, Cosmos DB, and Azure Kubernetes Service. Learn to deploy scalable web applications, configure networking and security, and implement infrastructure-as-code with ARM templates. Hands-on labs guide you through resource provisioning, cost management, and best practices for high availability and disaster recovery in Azure.\n",
            "\n",
            "Course: Containerization with Docker and Kubernetes\n",
            "Description: Learn container fundamentals with Docker: images, containers, and Compose. Then advance to Kubernetes for orchestration: pods, deployments, services, and ingress. This course covers cluster provisioning, autoscaling, rolling updates, and Helm chart packaging. Hands-on labs deploy microservices architectures on a local or cloud-based Kubernetes cluster, ensuring reliability, scalability, and streamlined DevOps workflows.\n",
            "\n",
            "Course: DevOps Practices and CI/CD\n",
            "Description: Adopt DevOps methodologies to accelerate software delivery. Explore version control with Git, continuous integration with Jenkins or GitHub Actions, infrastructure-as-code with Terraform, and automated testing frameworks. You’ll implement CI/CD pipelines, container registry integration, and blue-green deployments. Through practical labs, learn monitoring with Prometheus and Grafana, fostering a culture of collaboration and rapid iteration.\n",
            "\n",
            "Course: MLOps: Productionizing Machine Learning\n",
            "Description: Master the practices needed to deploy and maintain ML models at scale. Topics include model versioning with MLflow, containerization, CI/CD for ML, monitoring with Prometheus, and data drift detection. You’ll build end-to-end pipelines that automate training, testing, deployment, and governance, ensuring robust, reproducible, and compliant machine learning systems in production environments.\n",
            "\n",
            "Course: Data Engineering on AWS\n",
            "Description: Build scalable data pipelines using AWS services. This course covers S3 data lakes, AWS Glue ETL jobs, AWS Lambda for serverless transformations, Amazon Redshift for warehousing, and AWS Kinesis for streaming ingestion. You’ll design end-to-end pipelines, automate workflows with AWS Step Functions, and monitor performance using CloudWatch, enabling robust, cost-effective data engineering solutions on the AWS cloud.\n",
            "\n",
            "**Relevance Evaluation:** Review the retrieved courses to assess relevance. The output lists up to 5 courses based on semantic similarity to the query, but no explanations are generated due to using only text-embedding-3-small.\n",
            "\n",
            "### Test Profile 3\n",
            "**Query:** My background is in ML fundamentals; I’d like to specialize in neural networks and production workflows.\n",
            "**Retrieved Courses:**\n",
            "Course: MLOps: Productionizing Machine Learning\n",
            "Description: Master the practices needed to deploy and maintain ML models at scale. Topics include model versioning with MLflow, containerization, CI/CD for ML, monitoring with Prometheus, and data drift detection. You’ll build end-to-end pipelines that automate training, testing, deployment, and governance, ensuring robust, reproducible, and compliant machine learning systems in production environments.\n",
            "\n",
            "Course: Foundations of Machine Learning\n",
            "Description: Understand foundational machine learning algorithms including regression, classification, clustering, and dimensionality reduction. This course covers data pre-processing, feature engineering, model selection, hyperparameter tuning, and evaluation metrics. Hands-on labs use scikit-learn and Python to implement end-to-end workflows on real-world datasets, preparing learners for practical machine learning applications with interactive engaging exercises.\n",
            "\n",
            "Course: Deep Learning with TensorFlow and Keras\n",
            "Description: Explore neural network architectures using TensorFlow and Keras frameworks. This course covers feedforward networks, convolutional neural networks, recurrent neural networks, and transfer learning. Learn to build, train, evaluate, and optimize deep learning models for image classification, sequence modeling, and text processing. Includes hands-on labs and real-world project implementations with interactive exercises.\n",
            "\n",
            "Course: Python Programming for Data Science\n",
            "Description: Learn Python fundamentals for data science: variables, control flow, functions, and object-oriented programming. Advance to data handling with pandas, numerical computing with NumPy, and basic plotting with matplotlib. You’ll build reproducible data workflows, clean and transform datasets, and perform exploratory analysis, laying the groundwork for machine learning and statistical modeling projects.\n",
            "\n",
            "Course: Reinforcement Learning Basics\n",
            "Description: Get introduced to reinforcement learning paradigms, including Markov decision processes, Q-learning, policy gradients, and actor-critic methods. Learn to formulate environments, design reward functions, and implement agents using OpenAI Gym and TensorFlow. Through guided labs you’ll train agents for classic control tasks and grid-world scenarios, exploring exploration-exploitation trade-offs and model-free learning techniques.\n",
            "\n",
            "**Relevance Evaluation:** Review the retrieved courses to assess relevance. The output lists up to 5 courses based on semantic similarity to the query, but no explanations are generated due to using only text-embedding-3-small.\n",
            "\n",
            "### Test Profile 4\n",
            "**Query:** I want to learn to build and deploy microservices with Kubernetes—what courses fit best?\n",
            "**Retrieved Courses:**\n",
            "Course: Containerization with Docker and Kubernetes\n",
            "Description: Learn container fundamentals with Docker: images, containers, and Compose. Then advance to Kubernetes for orchestration: pods, deployments, services, and ingress. This course covers cluster provisioning, autoscaling, rolling updates, and Helm chart packaging. Hands-on labs deploy microservices architectures on a local or cloud-based Kubernetes cluster, ensuring reliability, scalability, and streamlined DevOps workflows.\n",
            "\n",
            "Course: Cloud Computing with Azure\n",
            "Description: Master Microsoft Azure’s core services: virtual machines, Azure Functions, Azure SQL Database, Cosmos DB, and Azure Kubernetes Service. Learn to deploy scalable web applications, configure networking and security, and implement infrastructure-as-code with ARM templates. Hands-on labs guide you through resource provisioning, cost management, and best practices for high availability and disaster recovery in Azure.\n",
            "\n",
            "Course: APIs and Microservices Architecture\n",
            "Description: Design and implement RESTful and GraphQL APIs using Node.js, Express, or Python FastAPI. Learn microservices patterns: service discovery, circuit breakers, and API gateways. Topics include containerized deployment, versioning strategies, and security best practices (OAuth2, JWT). Labs guide you through building, testing, and deploying interconnected services, enabling scalable, maintainable distributed systems.\n",
            "\n",
            "Course: MLOps: Productionizing Machine Learning\n",
            "Description: Master the practices needed to deploy and maintain ML models at scale. Topics include model versioning with MLflow, containerization, CI/CD for ML, monitoring with Prometheus, and data drift detection. You’ll build end-to-end pipelines that automate training, testing, deployment, and governance, ensuring robust, reproducible, and compliant machine learning systems in production environments.\n",
            "\n",
            "Course: DevOps Practices and CI/CD\n",
            "Description: Adopt DevOps methodologies to accelerate software delivery. Explore version control with Git, continuous integration with Jenkins or GitHub Actions, infrastructure-as-code with Terraform, and automated testing frameworks. You’ll implement CI/CD pipelines, container registry integration, and blue-green deployments. Through practical labs, learn monitoring with Prometheus and Grafana, fostering a culture of collaboration and rapid iteration.\n",
            "\n",
            "**Relevance Evaluation:** Review the retrieved courses to assess relevance. The output lists up to 5 courses based on semantic similarity to the query, but no explanations are generated due to using only text-embedding-3-small.\n",
            "\n",
            "### Test Profile 5\n",
            "**Query:** I’m interested in blockchain and smart contracts but have no prior experience. Which courses do you suggest?\n",
            "**Retrieved Courses:**\n",
            "Course: Blockchain Technology and Smart Contracts\n",
            "Description: Understand blockchain fundamentals: cryptographic hashing, consensus algorithms, and distributed ledgers. Learn to develop smart contracts using Solidity on Ethereum. Topics include token standards (ERC-20, ERC-721), decentralized application patterns, and security best practices. Hands-on labs deploy contracts, interact via Web3.js, and build a simple decentralized marketplace.\n",
            "\n",
            "Course: Augmented and Virtual Reality Development\n",
            "Description: Dive into AR/VR concepts, device ecosystems, and development frameworks like Unity and Unreal Engine. Learn to build immersive experiences, handle 3D assets, and implement input interactions. Topics cover spatial computing, UI/UX for XR, and performance optimization. Through labs, you’ll create both AR and VR prototypes for education, training, or entertainment use cases.\n",
            "\n",
            "Course: Cybersecurity Fundamentals\n",
            "Description: Get introduced to cybersecurity principles: threat modeling, encryption, network security, and incident response. Learn about common vulnerabilities (OWASP Top 10), secure coding practices, and vulnerability assessment tools. Hands-on labs include configuring firewalls, running penetration tests with Kali Linux, and implementing multi-factor authentication, preparing you to protect systems and data against modern cyber threats.\n",
            "\n",
            "Course: Reinforcement Learning Basics\n",
            "Description: Get introduced to reinforcement learning paradigms, including Markov decision processes, Q-learning, policy gradients, and actor-critic methods. Learn to formulate environments, design reward functions, and implement agents using OpenAI Gym and TensorFlow. Through guided labs you’ll train agents for classic control tasks and grid-world scenarios, exploring exploration-exploitation trade-offs and model-free learning techniques.\n",
            "\n",
            "Course: NoSQL Databases and MongoDB\n",
            "Description: Explore NoSQL paradigms: key-value, document, column-family, and graph databases. Deep dive into MongoDB: CRUD operations, indexing, aggregation pipeline, replication, and sharding. You’ll design flexible schemas for modern applications, implement transactions, and optimize performance. Through hands-on exercises, build a highly available, horizontally scalable document store and apply best practices for data modeling.\n",
            "\n",
            "**Relevance Evaluation:** Review the retrieved courses to assess relevance. The output lists up to 5 courses based on semantic similarity to the query, but no explanations are generated due to using only text-embedding-3-small.\n"
          ]
        }
      ],
      "source": [
        "# Evaluate each query using the RAG-like chain\n",
        "for i, query in enumerate(sample_queries, 1):\n",
        "    print(f\"\\n### Test Profile {i}\")\n",
        "    print(f\"**Query:** {query}\")\n",
        "    try:\n",
        "        response = rag_chain(query)\n",
        "        print(\"**Retrieved Courses:**\")\n",
        "        print(response)\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing query {i}: {e}\")\n",
        "    print(\"\\n**Relevance Evaluation:** Review the retrieved courses to assess relevance. The output lists up to 5 courses based on semantic similarity to the query, but no explanations are generated due to using only text-embedding-3-small.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Notes\n",
        "\n",
        "- The system uses `chromadb.Client()` with an in-memory collection named 'rajcourserecs' for the vector store.\n",
        "- Embeddings are generated using `text-embedding-3-small`, and retrieval is based on semantic similarity.\n",
        "- Due to the limitation of `text-embedding-3-small` (no text generation capability), the pipeline returns formatted retrieved documents instead of generating reasoned recommendations.\n",
        "- Ensure the .env file is correctly formatted and the `text-embedding-3-small` deployment is set up in the Azure Portal before running.\n",
        "- If the dataset URL is inaccessible, download the CSV and load it via `pd.read_csv('local_path.csv')`.\n",
        "- Note: `chromadb.Client()` stores data in memory, so the collection resets if the notebook session ends.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "genai",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
