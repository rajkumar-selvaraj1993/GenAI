{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SpVgBlJNayoI"
      },
      "source": [
        "# Course Recommendation Engine with RAG and ChromaDB (In-Memory) Using text-embedding-3-small\n",
        "\n",
        "This notebook implements a course recommendation engine for Assignment 2 using a Retrieval-Augmented Generation (RAG)-like approach. It fetches a course catalog from a provided URL, generates embeddings with Azure OpenAI's `text-embedding-3-small` model, stores them in an in-memory ChromaDB vector store using `chromadb.Client()` with a collection named 'rajcourserecs', and retrieves relevant courses via semantic search. Due to the limitation of `text-embedding-3-small` (it only supports embeddings, not text generation), the pipeline returns formatted retrieved documents instead of generating reasoned recommendations. The implementation fixes `python-dotenv` parsing errors and ensures correct Azure deployment names."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28d272cd-4e31-40aa-bbb4-0be0a1f49a14",
        "outputId": "9732f606-6c04-4ad7-e0e6-b4d644fa5aa4"
      },
      "outputs": [],
      "source": [
        "!python -m pip install langchain langchain-openai pandas openai python-dotenv chromadb --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bLonIlavDBci",
        "outputId": "723d17aa-3376-4997-9988-a995acd2b072"
      },
      "outputs": [],
      "source": [
        "!python -m pip install pypdf --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "Ja6U3t6abVpU"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Python-dotenv could not parse statement starting at line 26\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Environment variables loaded successfully.\n",
            "Current date and time: 11:52 AM , September 26, 2025\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "from datetime import datetime\n",
        "from langchain_openai import AzureChatOpenAI\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "# Load environment variables from .env file\n",
        "load_dotenv()\n",
        "\n",
        "embedding_model_name = \"text-embedding-3-small\"\n",
        "embedding_deployment_name = \"text-embedding-3-small\"  # Replace with your Azure deployment name for text-embedding-3-small\n",
        "\n",
        "# Verify environment variables\n",
        "assert os.environ.get(\"AZURE_OPENAI_ENDPOINT\"), \"AZURE_OPENAI_ENDPOINT not set in .env\"\n",
        "assert os.environ.get(\"AZURE_OPENAI_API_KEY\"), \"AZURE_OPENAI_API_KEY not set in .env\"\n",
        "assert os.environ.get(\"AZURE_OPENAI_API_VERSION\", \"2024-06-01\"), \"AZURE_OPENAI_API_VERSION not set in .env\"\n",
        "\n",
        "print(\"Environment variables loaded successfully.\")\n",
        "print(f\"Current date and time: {datetime.now().strftime('%I:%M %p %Z, %B %d, %Y')}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "MGhs4RN7vgXG"
      },
      "outputs": [],
      "source": [
        "course_catalog_url = \"https://raw.githubusercontent.com/Bluedata-Consulting/GAAPB01-training-code-base/refs/heads/main/Assignments/assignment2dataset.csv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "nhl29sxXD085"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>course_id</th>\n",
              "      <th>title</th>\n",
              "      <th>description</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>C001</td>\n",
              "      <td>Foundations of Machine Learning</td>\n",
              "      <td>Understand foundational machine learning algor...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>C002</td>\n",
              "      <td>Deep Learning with TensorFlow and Keras</td>\n",
              "      <td>Explore neural network architectures using Ten...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>C003</td>\n",
              "      <td>Natural Language Processing Fundamentals</td>\n",
              "      <td>Dive into NLP techniques for processing and un...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>C004</td>\n",
              "      <td>Computer Vision and Image Processing</td>\n",
              "      <td>Learn the principles of computer vision and im...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>C005</td>\n",
              "      <td>Reinforcement Learning Basics</td>\n",
              "      <td>Get introduced to reinforcement learning parad...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  course_id                                     title  \\\n",
              "0      C001           Foundations of Machine Learning   \n",
              "1      C002   Deep Learning with TensorFlow and Keras   \n",
              "2      C003  Natural Language Processing Fundamentals   \n",
              "3      C004      Computer Vision and Image Processing   \n",
              "4      C005             Reinforcement Learning Basics   \n",
              "\n",
              "                                         description  \n",
              "0  Understand foundational machine learning algor...  \n",
              "1  Explore neural network architectures using Ten...  \n",
              "2  Dive into NLP techniques for processing and un...  \n",
              "3  Learn the principles of computer vision and im...  \n",
              "4  Get introduced to reinforcement learning parad...  "
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the course catalog\n",
        "try:\n",
        "    courses = pd.read_csv(course_catalog_url)\n",
        "except Exception as e:\n",
        "    print(f\"Error loading dataset: {e}\")\n",
        "    raise\n",
        "\n",
        "# Display first few rows to verify\n",
        "courses.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "plYaZJcrwZrd",
        "outputId": "494890bf-219a-47ff-fdb8-6c3806a33f5d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of courses loaded:\n",
            "25\n"
          ]
        }
      ],
      "source": [
        "# Verify the number of courses loaded\n",
        "print(\"Number of courses loaded:\")\n",
        "print(len(courses))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "HVLYgpziwdKD"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sample course description:\n",
            "Understand foundational machine learning algorithms including regression, classification, clustering, and dimensionality reduction. This course covers data pre-processing, feature engineering, model selection, hyperparameter tuning, and evaluation metrics. Hands-on labs use scikit-learn and Python to implement end-to-end workflows on real-world datasets, preparing learners for practical machine learning applications with interactive engaging exercises.\n"
          ]
        }
      ],
      "source": [
        "# Display a sample course description\n",
        "print(\"Sample course description:\")\n",
        "print(courses['description'][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "msEaKLKqwiOE",
        "outputId": "030bb343-243e-4718-8db3-d4a466eba058"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average description length (characters): 408.96\n"
          ]
        }
      ],
      "source": [
        "# Check average description length\n",
        "avg_length = sum(len(str(desc)) for desc in courses['description']) / len(courses)\n",
        "print(\"Average description length (characters):\", avg_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qM6hV4DjwkIe",
        "outputId": "95a1e500-863d-4509-cce9-e79d5f0638e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of document splits:\n",
            "25\n"
          ]
        }
      ],
      "source": [
        "# Split long descriptions to avoid exceeding embedding limits\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=3500, chunk_overlap=500)\n",
        "docs = []\n",
        "doc_ids = []\n",
        "metadatas = []\n",
        "for i, (title, desc) in enumerate(zip(courses['title'], courses['description'])):\n",
        "    desc = str(desc)  # Ensure description is a string\n",
        "    if len(desc.strip()) > 100:  # Skip short or empty descriptions\n",
        "        split_docs = text_splitter.split_text(desc)\n",
        "        for j, split in enumerate(split_docs):\n",
        "            docs.append(split)\n",
        "            doc_ids.append(f\"{i}_{j}\")\n",
        "            metadatas.append({\"title\": str(title)})\n",
        "\n",
        "print(\"Number of document splits:\")\n",
        "print(len(docs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YpYTraoSwmUj",
        "outputId": "34f34a36-63ad-4808-decc-12df8830c92b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sample document:\n",
            "ID: 0_0\n",
            "Metadata: {'title': 'Foundations of Machine Learning'}\n",
            "Content: Understand foundational machine learning algorithms including regression, classification, clustering, and dimensionality reduction. This course covers data pre-processing, feature engineering, model s...\n"
          ]
        }
      ],
      "source": [
        "# Display a sample split document\n",
        "print(\"Sample document:\")\n",
        "print(f\"ID: {doc_ids[0]}\")\n",
        "print(f\"Metadata: {metadatas[0]}\")\n",
        "print(f\"Content: {docs[0][:200]}...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "l2B32z8TcWoU"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from langchain_openai import AzureOpenAIEmbeddings\n",
        "embeddings = AzureOpenAIEmbeddings(model=embedding_model_name,deployment=embedding_deployment_name, azure_endpoint=os.environ.get(\"AZURE_OPENAI_ENDPOINT\"),api_key=os.environ.get(\"AZURE_OPENAI_API_KEY\"),api_version=os.environ.get(\"AZURE_OPENAI_API_VERSION\", \"2024-06-01\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "VLwnR76SMPsH"
      },
      "outputs": [],
      "source": [
        "import chromadb\n",
        "\n",
        "# Initialize ChromaDB client (in-memory)\n",
        "chroma_client = chromadb.Client()\n",
        "\n",
        "# Create collection\n",
        "try:\n",
        "    # Delete existing collection if it exists to avoid conflicts\n",
        "    chroma_client.delete_collection(name=\"rajcourserecs\")\n",
        "except:\n",
        "    pass\n",
        "collection = chroma_client.create_collection(name=\"rajcourserecs\", metadata={\"use_type\": \"COURSE_RECOMMENDATION\"})\n",
        "\n",
        "# Generate embeddings for documents\n",
        "try:\n",
        "    embeddings_list = embeddings.embed_documents(docs)\n",
        "except Exception as e:\n",
        "    print(f\"Error generating embeddings: {e}\")\n",
        "    raise\n",
        "\n",
        "# Add documents to the collection\n",
        "try:\n",
        "    collection.add(\n",
        "        documents=docs,\n",
        "        ids=doc_ids,\n",
        "        metadatas=metadatas,\n",
        "        embeddings=embeddings_list\n",
        "    )\n",
        "except Exception as e:\n",
        "    print(f\"Error adding documents to collection: {e}\")\n",
        "    raise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of docs in vector DB:\n",
            "25\n"
          ]
        }
      ],
      "source": [
        "# Verify the number of documents in the collection\n",
        "print(\"Number of docs in vector DB:\")\n",
        "print(collection.count())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Custom retriever function for ChromaDB\n",
        "def chroma_retriever(query, k=10):\n",
        "    try:\n",
        "        query_embedding = embeddings.embed_query(query)\n",
        "        results = collection.query(\n",
        "            query_embeddings=[query_embedding],\n",
        "            n_results=k,\n",
        "            include=[\"documents\", \"metadatas\", \"distances\"]\n",
        "        )\n",
        "        # Convert to LangChain Document format for compatibility\n",
        "        from langchain_core.documents import Document\n",
        "        return [Document(page_content=doc, metadata=meta)\n",
        "                for doc, meta in zip(results['documents'][0], results['metadatas'][0])]\n",
        "    except Exception as e:\n",
        "        print(f\"Error in retriever: {e}\")\n",
        "        return []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "id": "mfJHg61Uw6BP",
        "outputId": "3ce3f2b9-d711-4f4c-9054-0000508f9b9f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of retrieved documents:\n",
            "10\n"
          ]
        }
      ],
      "source": [
        "# Test the retriever with a sample query\n",
        "test_query = \"data visualization courses\"\n",
        "retrieved_docs = chroma_retriever(test_query)\n",
        "print(\"Number of retrieved documents:\")\n",
        "print(len(retrieved_docs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DNIGp-p9w6BV",
        "outputId": "3910a673-677b-4cea-8fcd-95e453bab413"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "page_content='Transform raw data into compelling visual stories using Tableau. Learn to connect to diverse data sources, create interactive dashboards, and apply best practices in chart selection. Topics include calculated fields, parameters, LOD expressions, and storytelling features. Through real-world case studies, you’ll design user-driven analytics that reveal trends and drive data-informed decision making.' metadata={'title': 'Data Visualization with Tableau'}\n"
          ]
        }
      ],
      "source": [
        "# Display a sample retrieved course\n",
        "if retrieved_docs:\n",
        "    print(retrieved_docs[0])\n",
        "else:\n",
        "    print(\"No documents retrieved.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6tMaR7AVw6BV",
        "outputId": "c12e2a21-2685-4760-83c1-302cc27b4642"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "page_content='Get introduced to R for statistical computing and graphics. Topics include data structures, control flow, and functional programming. Use tidyverse libraries—dplyr, ggplot2, tidyr—for data manipulation and visualization. Explore hypothesis testing, regression analysis, and ANOVA. Through labs, apply statistical methods to real-world datasets and communicate results with reproducible R Markdown reports.' metadata={'title': 'R Programming and Statistical Analysis'}\n"
          ]
        }
      ],
      "source": [
        "# Display another sample retrieved course\n",
        "if len(retrieved_docs) > 1:\n",
        "    print(retrieved_docs[1])\n",
        "else:\n",
        "    print(\"Not enough documents retrieved.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z2PHFzF5MPsJ"
      },
      "source": [
        "### Implementing RAG Chain with LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize the text-generation LLM\n",
        "llm = AzureChatOpenAI(model='gpt4o')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define the prompt template for the LLM\n",
        "prompt_template = PromptTemplate(\n",
        "    input_variables=[\"query\", \"context\"],\n",
        "    template=\"\"\"You are a course recommendation assistant. Based on the user's query and their background, recommend up to 5 relevant courses from the provided course descriptions. Provide a clear, concise explanation for each recommendation, explaining why it suits the user's needs or interests. Ensure the response is tailored to the user's background and interests as mentioned in the query.\n",
        "\n",
        "User Query: {query}\n",
        "\n",
        "Retrieved Courses:\n",
        "{context}\n",
        "\n",
        "Recommendations:\"\"\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function to format retrieved documents and deduplicate by title\n",
        "def format_docs(docs):\n",
        "    unique_docs = []\n",
        "    seen_titles = set()\n",
        "    for doc in docs:\n",
        "        title = doc.metadata['title']\n",
        "        if title not in seen_titles:\n",
        "            unique_docs.append(f\"Course: {title}\\nDescription: {doc.page_content}\")\n",
        "            seen_titles.add(title)\n",
        "        if len(unique_docs) == 5:\n",
        "            break\n",
        "    return \"\\n\\n\".join(unique_docs) if unique_docs else \"No relevant courses found.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define the RAG chain with LLM call\n",
        "def rag_chain(query):\n",
        "    try:\n",
        "        # Retrieve relevant documents\n",
        "        retrieved_docs = chroma_retriever(query, k=10)\n",
        "        if not retrieved_docs:\n",
        "            return \"No relevant courses found.\"\n",
        "        \n",
        "        # Format retrieved documents\n",
        "        context = format_docs(retrieved_docs)\n",
        "        \n",
        "        # Create the prompt with query and context\n",
        "        prompt = prompt_template.format(query=query, context=context)\n",
        "        \n",
        "        # Call the LLM to generate recommendations\n",
        "        response = llm.invoke(prompt)\n",
        "        \n",
        "        # Return the LLM's response\n",
        "        return response.content\n",
        "    except Exception as e:\n",
        "        return f\"Error invoking RAG chain: {e}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sample queries\n",
        "sample_queries = [\n",
        "    \"I’ve completed the ‘Python Programming for Data Science’ course and enjoy data visualization. What should I take next?\",\n",
        "    \"I know Azure basics and want to manage containers and build CI/CD pipelines. Recommend courses.\",\n",
        "    \"My background is in ML fundamentals; I’d like to specialize in neural networks and production workflows.\",\n",
        "    \"I want to learn to build and deploy microservices with Kubernetes—what courses fit best?\",\n",
        "    \"I’m interested in blockchain and smart contracts but have no prior experience. Which courses do you suggest?\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "### Test Profile 1\n",
            "**Query:** I’ve completed the ‘Python Programming for Data Science’ course and enjoy data visualization. What should I take next?\n",
            "**Recommended Courses:**\n",
            "Based on your completion of the 'Python Programming for Data Science' course and your interest in data visualization, here are five course recommendations that will help you advance your skills in data visualization and expand your data analytics capabilities:\n",
            "\n",
            "1. **Data Visualization with Tableau**\n",
            "   - **Why it suits you:** This course will build on your existing Python skills by equipping you with the ability to create interactive and compelling visual representations of data using Tableau. It focuses on practical applications and storytelling through data, which is essential for any data professional. Learning Tableau will also enhance your ability to communicate insights effectively to various stakeholders.\n",
            "\n",
            "2. **R Programming and Statistical Analysis**\n",
            "   - **Why it suits you:** While this course introduces R, a widely-used programming language in data science and statistics, it also emphasizes data visualization with the ggplot2 package. Your prior knowledge of Python programming will make it easier to grasp the concepts in R, especially in data manipulation and visualization, complementing your existing skill set.\n",
            "\n",
            "3. **Big Data Analytics with Spark**\n",
            "   - **Why it suits you:** This course is ideal if you want to scale your data visualization and analysis skills to handle larger datasets effectively. Learning Spark will enhance your understanding of processing big data, which is increasingly vital in the data science field. Additionally, you'll gain experience in creating interactive dashboards that can visualize insights from massive datasets.\n",
            "\n",
            "4. **Computer Vision and Image Processing**\n",
            "   - **Why it suits you:** While this course focuses on visual data, it applies to a specialized area of data visualization. If you have any interest in visual data, image analysis, or working with multimedia data, this course will expand your knowledge of looking at data through a different lens. The hands-on labs will allow you to apply your Python skills in a new context.\n",
            "\n",
            "5. **Advanced Python for Data Science**\n",
            "   - **Why it suits you:** Though not listed in your original course selections, an advanced Python course focusing on data science applications could further enhance your ability to perform sophisticated data analysis and visualization tasks. Skills in advanced libraries such as Plotly and Seaborn for visualization, along with machine learning and advanced data manipulation techniques, will solidify your Python programming foundations.\n",
            "\n",
            "These recommendations will help you deepen your data visualization skills, expand your technical toolkit, and enhance your ability to analyze and convey insights from data effectively.\n",
            "\n",
            "**Relevance Evaluation:** The system retrieves up to 5 courses based on semantic similarity and uses an LLM to generate reasoned recommendations tailored to the user's query and background.\n",
            "\n",
            "### Test Profile 2\n",
            "**Query:** I know Azure basics and want to manage containers and build CI/CD pipelines. Recommend courses.\n",
            "**Recommended Courses:**\n",
            "Based on your background in Azure basics and your interest in managing containers and building CI/CD pipelines, here are five relevant courses that suit your needs:\n",
            "\n",
            "1. **Containerization with Docker and Kubernetes**\n",
            "   - This course is ideal for you as it dives directly into container fundamentals with Docker, which is essential for managing containers effectively. Furthermore, it transitions into Kubernetes for orchestration, enabling you to efficiently manage containerized applications in a scalable environment. The hands-on labs will provide you with practical experience managing microservices architectures, crucial for a deeper understanding of DevOps in container environments.\n",
            "\n",
            "2. **DevOps Practices and CI/CD**\n",
            "   - Since you mentioned building CI/CD pipelines, this course is a perfect match. It covers essential DevOps methodologies and focuses on tools like Jenkins and GitHub Actions for continuous integration. You'll gain hands-on experience with implementing CI/CD pipelines and integrating them into a containerized workflow, which is valuable for streamlining your deployment processes in Azure and leveraging the tools you’re already familiar with.\n",
            "\n",
            "3. **Cloud Computing with Azure**\n",
            "   - While you already have a grasp of Azure basics, this course will expand your knowledge by covering Azure Kubernetes Service, which is vital for container orchestration in the Azure cloud. You’ll also learn about deploying scalable web applications and infrastructure-as-code practices, helping you build a robust foundation to complement your container management and CI/CD initiatives.\n",
            "\n",
            "4. **MLOps: Productionizing Machine Learning**\n",
            "   - Although this course focuses primarily on machine learning, it includes critical concepts like containerization and CI/CD, which align with your goals. Learning about these practices in the context of handling ML models can provide you with unique insights into managing production-level containerized applications and pipelines, enhancing your overall skill set.\n",
            "\n",
            "5. **Data Engineering on AWS**\n",
            "   - While this course specifically focuses on AWS, understanding data engineering principles across cloud environments can be beneficial. Concepts such as data pipelines and automated workflows using cloud-native services can give you a broader perspective on best practices. This knowledge can be transferable to Azure and help strengthen your foundations in data-driven development in tandem with your container management skills.\n",
            "\n",
            "These courses will provide a well-rounded approach to container management and CI/CD pipelines, enhancing your existing Azure knowledge and preparing you for more advanced cloud development roles.\n",
            "\n",
            "**Relevance Evaluation:** The system retrieves up to 5 courses based on semantic similarity and uses an LLM to generate reasoned recommendations tailored to the user's query and background.\n",
            "\n",
            "### Test Profile 3\n",
            "**Query:** My background is in ML fundamentals; I’d like to specialize in neural networks and production workflows.\n",
            "**Recommended Courses:**\n",
            "Based on your background in machine learning fundamentals and your interest in specializing in neural networks and production workflows, here are five course recommendations tailored to your needs:\n",
            "\n",
            "1. **Deep Learning with TensorFlow and Keras**\n",
            "   - **Explanation**: This course is a direct fit for your interest in neural networks as it dives deep into various architectures such as convolutional and recurrent networks. You’ll gain hands-on experience in building, training, and optimizing deep learning models, which is essential for specializing in this area. The practical projects included will help solidify your understanding of applying neural network concepts to real-world problems.\n",
            "\n",
            "2. **MLOps: Productionizing Machine Learning**\n",
            "   - **Explanation**: Since you're keen on production workflows, this course will equip you with the skills to deploy and maintain ML models effectively. You’ll learn about essential practices such as containerization and CI/CD processes, which are crucial for transitioning from development to operational use in machine learning. This knowledge will enable you to manage ML systems at scale, aligning well with your goal of specializing in production workflows.\n",
            "\n",
            "3. **Foundations of Machine Learning**\n",
            "   - **Explanation**: Although you have a fundamental understanding of ML, this course can reinforce your knowledge of foundational algorithms and concepts that underpin more advanced topics like neural networks. It covers essential practices like feature engineering and model evaluation, which are critical as you move towards implementing neural networks in production.\n",
            "\n",
            "4. **Reinforcement Learning Basics**\n",
            "   - **Explanation**: While it takes a slightly different approach from traditional supervised learning, understanding reinforcement learning will broaden your skill set in machine learning. It introduces advanced learning paradigms that can complement your knowledge of neural networks and production workflows, especially in developing intelligent systems that adapt to their environments.\n",
            "\n",
            "5. **Python Programming for Data Science**\n",
            "   - **Explanation**: If you need to strengthen your programming skills, this course will provide a solid foundation in Python—a critical language for data science and ML. Mastering Python will be beneficial, as it’s the primary language used in many ML frameworks, including TensorFlow and Keras, facilitating your transition into more complex neural network projects and production processes.\n",
            "\n",
            "These courses collectively will enhance your expertise in neural networks and provide you with the production skills necessary for deploying machine learning solutions efficiently.\n",
            "\n",
            "**Relevance Evaluation:** The system retrieves up to 5 courses based on semantic similarity and uses an LLM to generate reasoned recommendations tailored to the user's query and background.\n",
            "\n",
            "### Test Profile 4\n",
            "**Query:** I want to learn to build and deploy microservices with Kubernetes—what courses fit best?\n",
            "**Recommended Courses:**\n",
            "Based on your interest in building and deploying microservices with Kubernetes, here are five recommended courses that align with your goals:\n",
            "\n",
            "1. **Containerization with Docker and Kubernetes**\n",
            "   - **Why it suits you**: This course provides a solid foundation in containerization using Docker, which is essential for microservices architecture. It covers Kubernetes for orchestration, enabling you to learn not just how to create and run containers, but also how to manage them effectively in production environments. With hands-on labs focusing on deploying microservices, this course is directly aligned with your goal of building scalable systems.\n",
            "\n",
            "2. **APIs and Microservices Architecture**\n",
            "   - **Why it suits you**: Understanding the design and implementation of APIs is crucial for microservices. This course specifically addresses RESTful and GraphQL APIs, along with microservices patterns, offering insights into service discovery and API gateways. The practicum on deploying containerized applications complements your Kubernetes learning, equipping you with the tools to create interconnected services effectively.\n",
            "\n",
            "3. **Cloud Computing with Azure**\n",
            "   - **Why it suits you**: While this course focuses on Microsoft Azure, it includes valuable knowledge about Azure Kubernetes Service (AKS), which is a managed Kubernetes offering. By learning to deploy scalable web applications in the cloud and understanding cost management and infrastructure-as-code, you'll develop skills that are essential for deploying microservices in real-world applications.\n",
            "\n",
            "4. **DevOps Practices and CI/CD**\n",
            "   - **Why it suits you**: Implementing DevOps practices is key to managing microservices effectively. This course covers CI/CD pipelines and automated testing, critical for deploying microservices in a rapid and reliable manner. By integrating DevOps methodologies, you'll improve your deployment practices, ensuring that services are not only built correctly but also delivered efficiently.\n",
            "\n",
            "5. **MLOps: Productionizing Machine Learning** (Optional but insightful)\n",
            "   - **Why it suits you**: If you're also interested in the intersection of microservices and machine learning, this course would help you understand how to deploy and maintain machine learning models alongside microservices. While not primarily focused on microservices, learning about productionizing machine learning can expand your skill set, especially if your microservices will leverage ML features.\n",
            "\n",
            "These courses collectively provide a well-rounded approach to mastering microservices with Kubernetes, covering essential aspects from containerization to deployment practices.\n",
            "\n",
            "**Relevance Evaluation:** The system retrieves up to 5 courses based on semantic similarity and uses an LLM to generate reasoned recommendations tailored to the user's query and background.\n",
            "\n",
            "### Test Profile 5\n",
            "**Query:** I’m interested in blockchain and smart contracts but have no prior experience. Which courses do you suggest?\n",
            "**Recommended Courses:**\n",
            "Based on your interest in blockchain and smart contracts, here are five relevant course recommendations that cater to your goals while considering your lack of prior experience:\n",
            "\n",
            "1. **Blockchain Technology and Smart Contracts**\n",
            "   - **Why This Course?** This is the most directly relevant course to your interests. It covers the fundamentals of blockchain technology, which is essential for understanding smart contracts. You'll learn about cryptographic hashing, consensus algorithms, and distributed ledgers. The course also provides practical experience in developing smart contracts with Solidity, making it an ideal starting point for your blockchain journey.\n",
            "\n",
            "2. **Cybersecurity Fundamentals**\n",
            "   - **Why This Course?** Blockchain security is a critical component of the technology. Understanding cybersecurity principles will provide you with a strong foundation for building secure smart contracts and decentralized applications. This course will equip you with knowledge about secure coding practices and vulnerabilities, which are crucial for ensuring the safety of your blockchain projects.\n",
            "\n",
            "3. **NoSQL Databases and MongoDB**\n",
            "   - **Why This Course?** As you delve into blockchain development, having knowledge of databases—especially NoSQL—is beneficial, particularly for decentralized applications that may require flexible data management solutions. This course will help you understand how to design and manage data in a way that complements your blockchain applications.\n",
            "\n",
            "4. **Augmented and Virtual Reality Development**\n",
            "   - **Why This Course?** While this course is not strictly about blockchain, it offers a unique perspective on how blockchain could be integrated with AR and VR technologies, such as in the creation of virtual marketplaces or tokenized digital assets. If you're interested in the broader applications of blockchain technology beyond just smart contracts, this course could broaden your understanding of where blockchain fits into emerging tech areas.\n",
            "\n",
            "5. **Reinforcement Learning Basics**\n",
            "   - **Why This Course?** This course may seem divergent from your primary interest, but understanding machine learning principles can be beneficial in the context of blockchain, especially in areas like smart contract optimization and automated trading. The analytical skills gained here could help you implement smarter and more efficient blockchain applications in the future.\n",
            "\n",
            "These courses together will provide you with a comprehensive understanding of blockchain and its related technologies, equipping you with the foundational skills you need to thrive in this field.\n",
            "\n",
            "**Relevance Evaluation:** The system retrieves up to 5 courses based on semantic similarity and uses an LLM to generate reasoned recommendations tailored to the user's query and background.\n"
          ]
        }
      ],
      "source": [
        "# Evaluate each query using the RAG chain\n",
        "for i, query in enumerate(sample_queries, 1):\n",
        "    print(f\"\\n### Test Profile {i}\")\n",
        "    print(f\"**Query:** {query}\")\n",
        "    try:\n",
        "        response = rag_chain(query)\n",
        "        print(\"**Recommended Courses:**\")\n",
        "        print(response)\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing query {i}: {e}\")\n",
        "    print(\"\\n**Relevance Evaluation:** The system retrieves up to 5 courses based on semantic similarity and uses an LLM to generate reasoned recommendations tailored to the user's query and background.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Notes\n",
        "\n",
        "- The system uses `chromadb.Client()` with an in-memory collection named 'rajcourserecs' for the vector store.\n",
        "- Embeddings are generated using `text-embedding-3-small`, and retrieval is based on semantic similarity.\n",
        "- Due to the limitation of `text-embedding-3-small` (no text generation capability), the pipeline returns formatted retrieved documents instead of generating reasoned recommendations.\n",
        "- The `python-dotenv` error is fixed by explicitly loading a valid .env file and validating environment variables.\n",
        "- Ensure the .env file is correctly formatted and the `text-embedding-3-small` deployment is set up in the Azure Portal before running.\n",
        "- If the dataset URL is inaccessible, download the CSV and load it via `pd.read_csv('local_path.csv')`.\n",
        "- Note: `chromadb.Client()` stores data in memory, so the collection resets if the notebook session ends.\n",
        "- Potential improvement: Add a precomputed explanation field to the dataset if available, though this requires external setup."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "genai",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
